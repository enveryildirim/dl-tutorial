{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_square(x):\n",
    "    return x * x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.61107034, 6.73507127])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform((10,10),4,)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.sqrt(abs(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*x + 1\n",
    "x = 2 y = 5\n",
    "x = 3 y = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([2,3,5])\n",
    "y_train = 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-20000.00000004 -29999.99999995 -50000.        ] -9995.00000001883\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function to be minimized\n",
    "def f(x, a, b):\n",
    "  return a*x + b\n",
    "\n",
    "# Define the derivative of the function\n",
    "def df(x,a,b):\n",
    "  deriv_a = x\n",
    "  deriv_b = 1\n",
    "  return deriv_a, deriv_b\n",
    "\n",
    "# Set the initial value of x\n",
    "a = np.random.randint(10)\n",
    "b = np.random.randint(10)\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set the maximum number of iterations\n",
    "max_iter = 100000\n",
    "\n",
    "# Set the initial value of the minimum\n",
    "f_min = float('inf')\n",
    "\n",
    "# Iterate over the number of iterations\n",
    "for i in range(max_iter):\n",
    "  # Calculate the gradient at the current value of x\n",
    "  gradient_a, gradient_b = df(x, a, b)\n",
    "\n",
    "  # Update the value of x using the gradient descent update rule\n",
    "  a = a - learning_rate * gradient_a\n",
    "  b = b - learning_rate * gradient_b\n",
    "\n",
    "  # Calculate the value of the function at the new value of x\n",
    "  y_pred = f(x,a,b)\n",
    "  error = mse(y, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Print the minimum value of the function\n",
    "print(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = f(x)\n",
    "err = np.mean(np.sqrt(abs(y - a*x + b)))\n",
    "d_err = 2 * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.11\n"
     ]
    }
   ],
   "source": [
    "# Define the function to be minimized\n",
    "def f(x):\n",
    "  return x**2 + 5*x + 6\n",
    "\n",
    "# Define the derivative of the function\n",
    "def df(x):\n",
    "  return 2*x + 5\n",
    "\n",
    "# Set the initial value of x\n",
    "x = 3\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set the maximum number of iterations\n",
    "max_iter = 100\n",
    "\n",
    "# Set the tolerance for the minimum value of the function\n",
    "tol = 1e-6\n",
    "\n",
    "# Set the initial value of the minimum\n",
    "f_min = float('inf')\n",
    "\n",
    "# Iterate over the number of iterations\n",
    "for i in range(max_iter):\n",
    "  # Calculate the gradient at the current value of x\n",
    "  gradient = df(x)\n",
    "\n",
    "  # Update the value of x using the gradient descent update rule\n",
    "  x = x - learning_rate * gradient\n",
    "\n",
    "  # Calculate the value of the function at the new value of x\n",
    "  f_x = f(x)\n",
    "\n",
    "  # Check if the new value of the function is less than the minimum\n",
    "  if f_x < f_min:\n",
    "    # If it is, update the minimum value\n",
    "    f_min = f_x\n",
    "\n",
    "  # Check if the tolerance has been reached\n",
    "  if abs(f_min - f_x) < tol:\n",
    "    # If it has, break out of the loop\n",
    "    break\n",
    "\n",
    "# Print the minimum value of the function\n",
    "print(f_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "958d8d14dabca165bcdfddd86cb9b453a60d55283e2799df101f99006878e2eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
